{"componentChunkName":"component---src-templates-post-template-jsx","path":"/python/django/drf-02-serializer/","result":{"data":{"site":{"siteMetadata":{"title":"Blog by 인간지능","subtitle":"깔끔한 프로그래밍","copyright":"© All rights reserved.","author":{"name":"인간지능","twitter":"#"},"disqusShortname":"bmh8993-github-io","url":"https://bmh8993.github.io/"}},"markdownRemark":{"id":"72d64661-2894-5611-a712-0cbb4c71b324","html":"<p>DRF의 serializer에 대해서 알아봅시다.</p>\n<p>DRF의 Serializer는 queryset이나 모델의 instance와 같은 복잡한 데이터를 json처럼 쉽게 사용 가능한 python data type으로 변환 시켜줍니다. 또한 validation도 검증해줍니다.<br>\n<br>\nSerializer의 의미에 대해서는 아래 포스트를 읽어보길 바랍니다.<br>\n<a href=\"https://bmh8993.github.io/cs/network/serialization/\">직렬화(serialisation)는 무엇인가</a><br>\n<br></p>\n<h2>1. Article object and serializer</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># news.models.py</span>\n\n<span class=\"token keyword\">from</span> django<span class=\"token punctuation\">.</span>db <span class=\"token keyword\">import</span> models\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Article</span><span class=\"token punctuation\">(</span>models<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    author <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span>max_length<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span>\n    title <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span>max_length<span class=\"token operator\">=</span><span class=\"token number\">120</span><span class=\"token punctuation\">)</span>\n    description <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span>max_length<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">)</span>\n    body <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>TextField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    location <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span>max_length<span class=\"token operator\">=</span><span class=\"token number\">120</span><span class=\"token punctuation\">)</span>\n    publication_date <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>DateField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    active <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>BooleanField<span class=\"token punctuation\">(</span>default<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    created_at <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>DateTimeField<span class=\"token punctuation\">(</span>auto_now_add<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    updated_at <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>DateTimeField<span class=\"token punctuation\">(</span>auto_now<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># news.serializers.py</span>\n\n<span class=\"token keyword\">from</span> rest_framework <span class=\"token keyword\">import</span> serializers\n<span class=\"token keyword\">from</span> <span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Article\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ArticleSerializer</span><span class=\"token punctuation\">(</span>serializers<span class=\"token punctuation\">.</span>Serializer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token builtin\">id</span> <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>IntegerField<span class=\"token punctuation\">(</span>read_only<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    author <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    title <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    description <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    body <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    location <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    publication_date <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>DateField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    active <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>BooleanField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    created_at <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>DateTimeField<span class=\"token punctuation\">(</span>read_only<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    updated_at <span class=\"token operator\">=</span> serializers<span class=\"token punctuation\">.</span>DateTimeField<span class=\"token punctuation\">(</span>read_only<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>2. Serializing objects</h2>\n<ul>\n<li>위에서 만든 ArticleSerializer로 article을 serialize 할 수 있습니다.</li>\n<li>모델 인스턴스를 파이썬 내부 데이터 타입으로 출력한 결과</li>\n<li>\n<p>미리 인스턴스를 만들고 진행했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token operator\">>></span><span class=\"token operator\">></span> article_instance <span class=\"token operator\">=</span> Article.objects.first<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> serializer <span class=\"token operator\">=</span> ArticleSerializer<span class=\"token punctuation\">(</span>article_instance<span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> serializer\nArticleSerializer<span class=\"token punctuation\">(</span><span class=\"token operator\">&lt;</span>Article: admin test_title<span class=\"token operator\">></span><span class=\"token punctuation\">)</span>:\n<span class=\"token function\">id</span> <span class=\"token operator\">=</span> serializers.IntegerField<span class=\"token punctuation\">(</span>read_only<span class=\"token operator\">=</span>True<span class=\"token punctuation\">)</span>\nauthor <span class=\"token operator\">=</span> serializers.CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntitle <span class=\"token operator\">=</span> serializers.CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndescription <span class=\"token operator\">=</span> serializers.CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nbody <span class=\"token operator\">=</span> serializers.CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nlocation <span class=\"token operator\">=</span> serializers.CharField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\npublication_date <span class=\"token operator\">=</span> serializers.DateField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nactive <span class=\"token operator\">=</span> serializers.BooleanField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncreated_at <span class=\"token operator\">=</span> serializers.DateTimeField<span class=\"token punctuation\">(</span>read_only<span class=\"token operator\">=</span>True<span class=\"token punctuation\">)</span>\nupdated_at <span class=\"token operator\">=</span> serializers.DateTimeField<span class=\"token punctuation\">(</span>read_only<span class=\"token operator\">=</span>True<span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> serializer.data\n<span class=\"token punctuation\">{</span><span class=\"token string\">'id'</span><span class=\"token builtin class-name\">:</span> <span class=\"token number\">1</span>, <span class=\"token string\">'author'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'admin'</span>, <span class=\"token string\">'title'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'test_title'</span>, <span class=\"token string\">'description'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'test_description'</span>, <span class=\"token string\">'body'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'test_body'</span>, <span class=\"token string\">'location'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'test_location'</span>, <span class=\"token string\">'publication_date'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'2020-04-02'</span>, <span class=\"token string\">'active'</span><span class=\"token builtin class-name\">:</span> True, <span class=\"token string\">'created_at'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'2020-04-02T10:57:03.725817Z'</span>, <span class=\"token string\">'updated_at'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'2020-04-02T10:57:03.725844Z'</span><span class=\"token punctuation\">}</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> type<span class=\"token punctuation\">(</span>serializer.data<span class=\"token punctuation\">)</span>\nrest_framework.utils.serializer_helpers.ReturnDict</code></pre></div>\n</li>\n<li>\n<p>python datatype에서 JSON으로 출력하기 위해서 아래와 같이 렌더링을 거쳐야합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token operator\">>></span><span class=\"token operator\">></span> from rest_framework.renderers <span class=\"token function\">import</span> JSONRenderer\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> json <span class=\"token operator\">=</span> JSONRenderer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>.render<span class=\"token punctuation\">(</span>serializer.data<span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> json\nb<span class=\"token string\">'{\"id\":1,\"author\":\"admin\",\"title\":\"test_title\",\"description\":\"test_description\",\"body\":\"test_body\",\"location\":\"test_location\",\"publication_date\":\"2020-04-02\",\"active\":true,\"created_at\":\"2020-04-02T10:57:03.725817Z\",\"updated_at\":\"2020-04-02T10:57:03.725844Z\"}'</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> type<span class=\"token punctuation\">(</span>json<span class=\"token punctuation\">)</span>\nbytes</code></pre></div>\n</li>\n</ul>\n<h2>3. Deserializing objects</h2>\n<ul>\n<li>\n<p>첫째로 파이썬 native datatype으로 변환합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token function\">import</span> io\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> from rest_framework.parsers <span class=\"token function\">import</span> JSONParser\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> stream <span class=\"token operator\">=</span> io.BytesIO<span class=\"token punctuation\">(</span>json<span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> data <span class=\"token operator\">=</span> JSONParser<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>.parse<span class=\"token punctuation\">(</span>stream<span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> data\n<span class=\"token punctuation\">{</span><span class=\"token string\">'id'</span><span class=\"token builtin class-name\">:</span> <span class=\"token number\">1</span>,\n<span class=\"token string\">'author'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'admin'</span>,\n<span class=\"token string\">'title'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'test_title'</span>,\n<span class=\"token string\">'description'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'test_description'</span>,\n<span class=\"token string\">'body'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'test_body'</span>,\n<span class=\"token string\">'location'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'test_location'</span>,\n<span class=\"token string\">'publication_date'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'2020-04-02'</span>,\n<span class=\"token string\">'active'</span><span class=\"token builtin class-name\">:</span> True,\n<span class=\"token string\">'created_at'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'2020-04-02T10:57:03.725817Z'</span>,\n<span class=\"token string\">'updated_at'</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">'2020-04-02T10:57:03.725844Z'</span><span class=\"token punctuation\">}</span></code></pre></div>\n</li>\n<li>deserializing한 데이터를 사용하기 전에 항상 <code class=\"language-text\">is_vaild()</code>함수를 호출해야합니다.</li>\n<li>DRF 코드를 보면 <code class=\"language-text\">.is_vaild()</code> before attempting, first, before accessing 등…기록되어져 있습니다.</li>\n<li>\n<p>특히, DRF 코드를 보면 <code class=\"language-text\">save()</code>하기 이전에 <code class=\"language-text\">is_vaild()</code>를 해야한다고 써있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">BaseSerializer</span><span class=\"token punctuation\">(</span>Field<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">save</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n<span class=\"token keyword\">assert</span> <span class=\"token builtin\">hasattr</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> <span class=\"token string\">'_errors'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>\n    <span class=\"token string\">'You must call `.is_valid()` before calling `.save()`.'</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></code></pre></div>\n</li>\n<li>\n<p>serializer에 instance를 전달하면 <code class=\"language-text\">update</code>를 실행하고, instance를 전달하지 않으면 <code class=\"language-text\">create</code>를 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># .save() will create a new instance</span>\nserializer <span class=\"token operator\">=</span> ArticleSerializer<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>data<span class=\"token punctuation\">)</span>\nserializer<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># .save() will update the existing `article` instance</span>\nserializer <span class=\"token operator\">=</span> ArticleSerializer<span class=\"token punctuation\">(</span>article_instance<span class=\"token punctuation\">,</span> data<span class=\"token operator\">=</span>data<span class=\"token punctuation\">)</span>\nserializer<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n</ul>\n<hr>\n<p>ref: <a href=\"https://dean-kim.github.io/rest_framework/2017/05/08/Django-REST-Framework-Serializers.html\">Dean’s blog</a></p>","fields":{"tagSlugs":["/tags/drf/"],"slug":"/python/django/drf-02-serializer/"},"frontmatter":{"title":"Django/DRF#02 Serializer","tags":["DRF"],"date":"2020-04-04T15:05:22.000Z","description":"DRF의 serializer에 대해서 알아봅시다.","path":"/python/django/drf-02-serializer/","category":"Django"},"tableOfContents":"<ul>\n<li><a href=\"/python/django/drf-02-serializer/#1-article-object-and-serializer\">1. Article object and serializer</a></li>\n<li><a href=\"/python/django/drf-02-serializer/#2-serializing-objects\">2. Serializing objects</a></li>\n<li><a href=\"/python/django/drf-02-serializer/#3-deserializing-objects\">3. Deserializing objects</a></li>\n</ul>","headings":[{"value":"1. Article object and serializer","depth":2},{"value":"2. Serializing objects","depth":2},{"value":"3. Deserializing objects","depth":2}]}},"pageContext":{"slug":"/python/django/drf-02-serializer/"}},"staticQueryHashes":[]}